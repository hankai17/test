##前言
- httpSM不断生产/触发/reenable cv(CacheVC)回调(openWriteMain) 从而完成文件写盘 
##写流程
- IOBufferBlock中累积的文件大于1M(1M - 2*sizeofDoc)或文件小于1M走die流程 才触发写盘(handleWriteLock)
```
              +---把cv入队 
handlewritelock--
               +---openWriteWriteDone 能调这函数说明该cv已经把doc拷贝到agg上了 dir_insert 计算nextkey  cv的iobuffblock引用计数--
两个过程都是在锁的加持下 每个过程都加一次锁的粒度也不大


handlewritelock---+--- openWriteCloseDataDone---openWriteCloseHead---updateVector---aggCopy
                                 ++++把cv入队 
die->openWriteClose->handlewritelock--
                                 ++++openWriteCloseDataDone (也是dir_insert 计算nextkey) ->openWriteCloseHead->updateVector(得到header_len)->aggWrit

```
- 对vol加锁 把cv插入agg队列中 如果幸运即没有io_process 则会同步调用agg_copy把cv上的doc拷贝到aggBuffer上  如果压力很大则仅仅是入队而已 然后返回contine 不会同步调用下面的openWriteWriteDone  上层process_event里不关心返回值 openwritemain中设置了cv的默认异步handler为openwritewritedone
  - aggWrite里遍历agg队列
      - 每个cv组成一个doc结构 并 初始化cv->dir用以记录该doc在磁盘中的位置
      - 如果hlen不为0 则依次把header data拷贝到doc尾巴处 从而拷贝到aggBuffer上  ats没有大小文件区别

    ```
struct Doc {
  uint32_t magic;        // DOC_MAGIC
  uint32_t len;          // length of this fragment (including hlen & sizeof(Doc), unrounded) // 1.25???
  uint64_t total_len;    // total length of document
  CryptoHash first_key;  ///< first key in object. // first_key是传进来的定值 一个文件的所有doc的first_key一样 earlies_key是算出来的
  CryptoHash key;        ///< Key for this doc.
  uint32_t hlen;         ///< Length of this header.
  uint32_t doc_type : 8; ///< Doc type - indicates the format of this structure and its content.
  uint32_t v_major : 8;  ///< Major version number.
  uint32_t v_minor : 8;  ///< Minor version number.
  uint32_t unused : 8;   ///< Unused, forced to zero.
  uint32_t sync_serial;
  uint32_t write_serial;
  uint32_t pinned; // pinned until
  uint32_t checksum;

  uint32_t data_len();
  uint32_t prefix_len();
  int single_fragment();
  int no_data_in_fragment();
  char *hdr();
  char *data();
};
    ``` 

- openWriteWriteDone  里调用dir_insert 根据传入的key(cv->key)找到对应的bucket 依次遍历桶直到找到一个空的位置 否则从freelist上pop出一个 用的是头插法 虽然前三个是连续的但也要调整pre next指针
  - 如果是小文件dir_insert流程 走的是die流程(openWriteCloseHeadDone) 在插/拆dir链(dir_insert)的时候 传入的是first_key 查找sb
  - 如果是大文件dir_insert流程 第一块内容doc用的是earliest_key查找sb 直到整个内容结束(openWriteCloseDataDone中) 而http_header_doc(openWriteCloseHeadDone)用的是first_key 作为传参
- 组doc流程
  - 如果是大文件 doc中的key是c->key 而http_header_doc的key 是pre(earlist_key)
  - 如果是小文件 doc中的key是earlist_key

##命中流程
- open_read中一旦发现命中 就调用handleRead流程 里面判断ramhit memhit hit 发起读盘异步操作(handleReadDone)
- handleReadDone中 调openReadStartHead  里面强转doc 校验first_key 把头读到vector里 选副本


##多副本流程与vector
- 场景 一个url有n多个版本比如 中文/英文/日文/韩文等 如果代理没有实现多副本流程 那么只缓存第一个请求 所以得实现多副本业务流程 根据请求头 缓存多个副本
比如请求中有Accept-Language: Chinese 那么得返中文版
- 另一个场景 同上这次是Encoding 有gzip或default 那么一个url同时考虑AL跟Encoding就会有 2 * 4 = 8个副本  显然是不合理的 所以这就是vary的作用 只根据一种方式进行协商 要么
根据lan协商 这样会有4个副本 要么根据encoding协商 这样会有两个副本
- 合并回源里  即使第一个cv的frag没有下完 其alternate是有内容的(set_http_info)  所以在openReadChooseWriter里会获得到第一个cv的alternate信息  然后在vector里选择最匹配的alternate(SelectFromAlternates判断多副本是否命中函数) 比如gizp 一个压缩一个非压缩请求 则就会匹配不到合适的alternate 就会重走open_write流程
- 测试时不要加via字段 
- 第一个副本在下载时  此时来第二个副本请求 第二个副本不会被缓存(openReadChoseWriter)
- 如果第一个副本已经下完毕 第二个副本来请求 那么会从磁盘上读出来(openReadStartHead)再比对
- 既然多副本的firstkey都相同那么 earlist_key是如何避免相同的???

##vol互斥与ptr指针
- od生命周期 open_write起始 close_write(openWriteCloseHeadDone)结束
- openReadChoseWriter是什么  多副本取header流程
